# Dependencies für LoRA/QLoRA Training
torch>=2.0.0
transformers>=4.30.0
peft>=0.4.0
datasets>=2.14.0
accelerate>=0.21.0
bitsandbytes>=0.41.0
scipy>=1.11.0
tensorboard>=2.13.0
# wandb>=0.15.0  # OPTIONAL: Für erweiterte Trainings-Überwachung
sentencepiece>=0.1.99
protobuf>=3.20.0

# Data processing
pandas>=2.0.0
numpy>=1.24.0
scikit-learn>=1.3.0
matplotlib>=3.7.0
seaborn>=0.12.0

# Document processing (PDF, Markdown, Word)
PyPDF2>=3.0.0
pdfplumber>=0.9.0
markdown>=3.4.0
beautifulsoup4>=4.12.0
python-docx>=0.8.11

# Ollama integration
requests>=2.31.0
httpx>=0.24.0

# Development
pytest>=7.4.0
black>=23.7.0
isort>=5.12.0
flake8>=6.0.0
mypy>=1.5.0

# Optional: Advanced training monitoring
# wandb>=0.15.0  # Cloud-based experiment tracking (requires account)

# Optional: For specific model support
einops>=0.6.1
xformers>=0.0.20
flash-attn>=2.0.0

# German language support
spacy>=3.6.0
de-core-news-sm @ https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.6.0/de_core_news_sm-3.6.0.tar.gz
pyyaml>=6.0

# Serving / API (Basis, falls kein getrenntes Deployment mit requirements_api.txt genutzt wird)
fastapi>=0.104.1
uvicorn[standard]>=0.24.0
pydantic>=2.5.0

# Optional High-Performance Inference (nur falls vLLM Routing / echtes Serving aktiviert wird)
# vllm>=0.3.3  # Aktivieren wenn echte vLLM Engine statt Fake-Modus genutzt werden soll

# Optional Embedding Similarity (Routing Phase 2)
# sentence-transformers>=2.2.2

# Hinweis: Für leichte Deployments kann alternativ nur requirements_api.txt installiert werden.
